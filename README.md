# ğŸ¤– Generative AI Chatbot â€“ From Scratch to Transformers

An **end-to-end Generative AI & NLP project** that builds a chatbot pipeline starting from raw conversational data and progressing through **statistical language models, RNN-based Seq2Seq architectures, and Transformer models**, ending with a fully interactive chatbot application.

This project is designed to demonstrate **deep understanding of NLP foundations and modern Large Language Model (LLM) architectures**, implemented using **PyTorch**.

---

## ğŸ“Œ Project Motivation

Large Language Models (LLMs) power modern AI applications such as chatbots, assistants, and text generation systems.  
This project was built to **understand how these systems work internally**, rather than using them as black boxes.

The focus is on:
- Building models **from scratch**
- Understanding architectural trade-offs
- Applying modern NLP pipelines in practice

---

## ğŸ§  Project Pipeline & Stages

| Stage | Description |
|------|------------|
| **Stage 1** | Data understanding and exploratory analysis |
| **Stage 2** | Text preprocessing and normalization |
| **Stage 3** | Custom NLP Dataset & DataLoader (tokenization, padding, batching) |
| **Stage 4** | Statistical language modeling using N-grams |
| **Stage 5** | Sequence-to-Sequence model using RNN Encoderâ€“Decoder |
| **Stage 6** | Transformer architecture implementation |
| **Stage 7** | Fine-tuning a pre-trained GPT-style language model |
| **Stage 8** | Model evaluation and performance analysis |
| **Stage 9** | Deployment of an interactive chatbot application |

---

## ğŸ§ª Key Concepts Covered

- Natural Language Processing (NLP)
- Text Preprocessing & Tokenization
- Language Modeling
- N-gram Statistical Models
- Word Embeddings
- Recurrent Neural Networks (RNNs)
- Encoderâ€“Decoder Architectures
- Transformers & Self-Attention
- Fine-tuning Large Language Models
- Model Evaluation & Inference
- Chatbot Deployment

---

## ğŸ› ï¸ Technologies Used

- **Python**
- **PyTorch**
- **Hugging Face Transformers**
- **NumPy / Pandas**
- **NLTK**
- **Scikit-learn**

---

## ğŸ“ Course Alignment

This project fully covers and exceeds the learning outcomes of:

- **Generative AI and LLMs: Architecture and Data Preparation**
- **Gen AI Foundational Models for NLP & Language Understanding**
