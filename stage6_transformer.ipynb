{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 1 — Imports & Config",
   "id": "b4bf0c565556a0ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:54:28.601074Z",
     "start_time": "2025-12-31T15:54:25.639721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "a50eb730f728ee1e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-31T15:54:38.862751Z",
     "start_time": "2025-12-31T15:54:38.199693Z"
    }
   },
   "cell_type": "markdown",
   "source": "Cell 2 — Positional Encoding",
   "id": "36a89ac290963f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:54:59.222991Z",
     "start_time": "2025-12-31T15:54:59.198086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ],
   "id": "e398c4aa88137d59",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 3 — Scaled Dot-Product Attention",
   "id": "9fc3e7a883581f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:55:20.012649Z",
     "start_time": "2025-12-31T15:55:19.985110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    d_k = Q.size(-1)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    attention = torch.softmax(scores, dim=-1)\n",
    "    output = torch.matmul(attention, V)\n",
    "    return output, attention"
   ],
   "id": "fa0feb35e2e7443f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 4 — Multi-Head Attention",
   "id": "6bbe95cacca5ebbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:55:57.283057Z",
     "start_time": "2025-12-31T15:55:57.224002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "\n",
    "        Q = self.W_q(Q)\n",
    "        K = self.W_k(K)\n",
    "        V = self.W_v(V)\n",
    "\n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        output, attention = scaled_dot_product_attention(Q, K, V, mask)\n",
    "\n",
    "        output = output.transpose(1, 2).contiguous()\n",
    "        output = output.view(batch_size, -1, self.num_heads * self.d_k)\n",
    "\n",
    "        return self.fc(output)"
   ],
   "id": "689d67b099876525",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 5 — Feed Forward Network",
   "id": "1db512cb96d2cf67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:56:35.340896Z",
     "start_time": "2025-12-31T15:56:35.298832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))"
   ],
   "id": "7ab675988056140f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 6 — Transformer Encoder Block",
   "id": "764d352f391eed6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:56:36.933942Z",
     "start_time": "2025-12-31T15:56:36.917679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.norm1(x + self.attn(x, x, x, mask))\n",
    "        x = self.norm2(x + self.ff(x))\n",
    "        return x\n"
   ],
   "id": "ad5750d5f6b4ed2b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 7 — Transformer Encoder",
   "id": "679e50230a32a638"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:57:25.028933Z",
     "start_time": "2025-12-31T15:57:25.003456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ],
   "id": "d0df60d6d71b1cca",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 8 — Test Forward Pass",
   "id": "3524faed0c8cf188"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:57:46.752423Z",
     "start_time": "2025-12-31T15:57:46.660951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VOCAB_SIZE = 10000\n",
    "D_MODEL = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 4\n",
    "D_FF = 256\n",
    "\n",
    "model = TransformerEncoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    d_ff=D_FF\n",
    ")\n",
    "\n",
    "x = torch.randint(0, VOCAB_SIZE, (32, 20))\n",
    "out = model(x)\n",
    "\n",
    "print(\"Output shape:\", out.shape)"
   ],
   "id": "e708c3891529f33a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 20, 128])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 9 — Masks (Padding & Look-Ahead",
   "id": "8d1c0f1afe81c3a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:58:51.052857Z",
     "start_time": "2025-12-31T15:58:51.024373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_padding_mask(seq, pad_idx=0):\n",
    "    # (batch, 1, 1, seq_len)\n",
    "    return (seq != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    # (1, 1, size, size)\n",
    "    mask = torch.tril(torch.ones(size, size))\n",
    "    return mask.unsqueeze(0).unsqueeze(1)"
   ],
   "id": "12ccd04a3c5bdc4a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 10 — Decoder Layer (Masked Self-Attention)",
   "id": "c37ff3767a554f96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:59:07.219204Z",
     "start_time": "2025-12-31T15:59:07.188047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_out, look_ahead_mask=None, padding_mask=None):\n",
    "        # Masked self-attention\n",
    "        x = self.norm1(x + self.self_attn(x, x, x, look_ahead_mask))\n",
    "        # Encoder–Decoder attention\n",
    "        x = self.norm2(x + self.enc_attn(x, enc_out, enc_out, padding_mask))\n",
    "        # Feed-forward\n",
    "        x = self.norm3(x + self.ff(x))\n",
    "        return x\n"
   ],
   "id": "63837a3607254334",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 11 — Transformer Decoder",
   "id": "26fa9eda1f720665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:59:23.753203Z",
     "start_time": "2025-12-31T15:59:23.730136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, enc_out, look_ahead_mask=None, padding_mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return self.fc(x)"
   ],
   "id": "751e6b2ed8620c22",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 12 — Full Transformer (Encoder + Decoder",
   "id": "a0e9e22ece04eea1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T15:59:38.215230Z",
     "start_time": "2025-12-31T15:59:38.187383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff)\n",
    "        self.decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        out = self.decoder(tgt, enc_out, tgt_mask, src_mask)\n",
    "        return out"
   ],
   "id": "16ccf79783192ac6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 13 — Quick Forward Test",
   "id": "62a5bc7d5c18bd06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T16:00:06.515817Z",
     "start_time": "2025-12-31T16:00:06.417576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VOCAB_SIZE = 10000\n",
    "D_MODEL = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 4\n",
    "D_FF = 256\n",
    "\n",
    "model = Transformer(VOCAB_SIZE, D_MODEL, NUM_LAYERS, NUM_HEADS, D_FF)\n",
    "\n",
    "src = torch.randint(0, VOCAB_SIZE, (32, 20))\n",
    "tgt = torch.randint(0, VOCAB_SIZE, (32, 20))\n",
    "\n",
    "src_mask = create_padding_mask(src)\n",
    "tgt_mask = create_look_ahead_mask(tgt.size(1))\n",
    "\n",
    "out = model(src, tgt, src_mask, tgt_mask)\n",
    "print(\"Transformer output shape:\", out.shape)"
   ],
   "id": "acb963a331adc038",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer output shape: torch.Size([32, 20, 10000])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 14 — Training Loop (Skeleton)",
   "id": "54fc0d95240dd602"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T16:00:26.950222Z",
     "start_time": "2025-12-31T16:00:26.346960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train_step(src, tgt):\n",
    "    model.train()\n",
    "\n",
    "    tgt_input = tgt[:, :-1]\n",
    "    tgt_real = tgt[:, 1:]\n",
    "\n",
    "    src_mask = create_padding_mask(src)\n",
    "    tgt_mask = create_look_ahead_mask(tgt_input.size(1))\n",
    "\n",
    "    preds = model(src, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "    loss = criterion(\n",
    "        preds.reshape(-1, VOCAB_SIZE),\n",
    "        tgt_real.reshape(-1)\n",
    "    )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "id": "2119711d75d532f1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cell 15 — Greedy Decoding (Inference)",
   "id": "9fe0181600edeaed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T16:00:41.278699Z",
     "start_time": "2025-12-31T16:00:41.239914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def greedy_decode(model, src, max_len=20, sos_idx=2, eos_idx=3):\n",
    "    model.eval()\n",
    "\n",
    "    src_mask = create_padding_mask(src)\n",
    "    enc_out = model.encoder(src, src_mask)\n",
    "\n",
    "    tgt = torch.tensor([[sos_idx]])\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        tgt_mask = create_look_ahead_mask(tgt.size(1))\n",
    "        out = model.decoder(tgt, enc_out, tgt_mask, src_mask)\n",
    "\n",
    "        next_token = out[:, -1].argmax(dim=-1).item()\n",
    "        tgt = torch.cat([tgt, torch.tensor([[next_token]])], dim=1)\n",
    "\n",
    "        if next_token == eos_idx:\n",
    "            break\n",
    "\n",
    "    return tgt"
   ],
   "id": "df1414ddc6a23f5b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b704b778ddd3a77a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "312b00a305c000a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c41c45dbc0319b03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
